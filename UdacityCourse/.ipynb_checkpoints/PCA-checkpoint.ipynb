{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef doPCA():\\n    from sklearn.decoposition import PCA \\n    pca = PCA(n_components=2)\\n    pca.fit(data)\\n    \\n    return pca\\n    \\n    \\npca = doPCA()\\nprint paca.explained_variance_ratio_\\nfrist_pc = pca.components_[0]\\nsecond_pc = pca.components_[1]\\n\\ntransformed_data = pca.transform(data)\\n\\nfor ii, jj in zip(transformed_data, data):\\n    plt.scatter( first_pc[0]*ii[0], first_pc[1] ** ii[0], color='r')\\n    plt.scatter(second_pc[0] ** ii[1], second_pc[1]**[1], color='c')\\n    plt.scatter(jj[0], jj[1], color='b')\\n    \\nplt.xlabel('bonus')\\nplt.ylabel('long-term incentive')\\n\\n\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def doPCA():\n",
    "    from sklearn.decoposition import PCA \n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(data)\n",
    "    \n",
    "    return pca\n",
    "    \n",
    "    \n",
    "pca = doPCA()\n",
    "print paca.explained_variance_ratio_\n",
    "frist_pc = pca.components_[0]\n",
    "second_pc = pca.components_[1]\n",
    "\n",
    "transformed_data = pca.transform(data)\n",
    "\n",
    "for ii, jj in zip(transformed_data, data):\n",
    "    plt.scatter( first_pc[0]*ii[0], first_pc[1] ** ii[0], color='r')\n",
    "    plt.scatter(second_pc[0] ** ii[1], second_pc[1]**[1], color='c')\n",
    "    plt.scatter(jj[0], jj[1], color='b')\n",
    "    \n",
    "plt.xlabel('bonus')\n",
    "plt.ylabel('long-term incentive')\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you can access this ...\n",
    "# how to visualizing it ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#code from Ud120-project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Faces recognition example using eigenfaces and SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom time import time\\nimport logging\\nimport pylab as pl\\nimport numpy as np\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from time import time\n",
    "import logging\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.cross_validation import train_test_split\\nfrom sklearn.datasets import fetch_lfw_people\\nfrom sklearn.grid_search import GridSearchCV\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.metrics import classifiaction_report\\nfrom sklearn.decomposition import RandomizedPCA\\nfrom sklearn.svm import SVC \\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import classifiaction_report\n",
    "from sklearn.decomposition import RandomizedPCA\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Display progress logs on stdout\\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')\\n\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDownload the data, if not already on disk and load it as numpy arrays\\nlfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\\n\\n# introspect the images arrasy to find the shapes(for plotting )\\n\\nn_samples, h, w = lfw_people.images.shape\\nnp.random.seed(42)\\n\\nX = lfw_people.data\\nn_featrues = X.shape[1]\\n\\nthe label to predict is the id of the person \\n\\ny = lfw_people.target\\ntarget_names = lfw_people.target_names\\nn_classes = tttttttarget_names.shape[0]\\n\\nprint \"Total dataset size:\"\\nprint \"n_samples: %d \" %n_smaples\\nprint \"n_featrues: %d\" %n_features\\nprint \"n_classes: %d\" %n_classes\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Download the data, if not already on disk and load it as numpy arrays\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "\n",
    "# introspect the images arrasy to find the shapes(for plotting )\n",
    "\n",
    "n_samples, h, w = lfw_people.images.shape\n",
    "np.random.seed(42)\n",
    "\n",
    "X = lfw_people.data\n",
    "n_featrues = X.shape[1]\n",
    "\n",
    "the label to predict is the id of the person \n",
    "\n",
    "y = lfw_people.target\n",
    "target_names = lfw_people.target_names\n",
    "n_classes = tttttttarget_names.shape[0]\n",
    "\n",
    "print \"Total dataset size:\"\n",
    "print \"n_samples: %d \" %n_smaples\n",
    "print \"n_featrues: %d\" %n_features\n",
    "print \"n_classes: %d\" %n_classes\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\\n\\n\\n# Compute a PCA (eigenfaces ) on the face dataset (treated as unlabeled # dataset )\\nunsupervised featrue extraction / dimensionality reduction \\n\\nn_componets = 150 \\nprint \"Extracting the top %d eigenfaces from %d from %d faces \"%(n_components, X_train.shape[0])\\n\\nt0 = time()\\npca = RandomizedPCA(n_components=n_components, whiten=True).fit(X_train)\\n\\nprint \"done in %0.3fs\" % (time() - t0)\\neigenfaces = pca.components_.reshpae(n_components, h, w)\\n\\nprint \"Projecting the input dat on the eigenfaces oothonormal basis\"\\nt0 = time()\\nX_train_pca = pac.transfrom(X_train)\\nX_test_pca = pca.transform(X_test)\\n\\nprint \"done in %0.3fs\" %(time() - t0)\\n\\n\\nprint \"Fitting the classifier to the training set\"\\n\\nt0 = time()\\n\\nparam_grid = {\\n    \\'C\\':[123, 5e3, ]\\n    \\'gamma\\': [0.0001, 0.0005, 0.001, ]\\n    \\n    }\\n    \\n# for sklearn version 0.15 or prior , the class_weight parameter value is auto\\'\\n\\nclf = GridSerchCV(SVC(kernel=\\'rbf\\', class_weight=\\'balanced\\'), param_grid)\\n\\nprint \"done in %0.0fs\" %(time() - t0)\\nprint \"Best estimator found by grid search:\\nprint clf.best_estimator_\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into a trainging and testigng set \n",
    "'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "# Compute a PCA (eigenfaces ) on the face dataset (treated as unlabeled # dataset )\n",
    "unsupervised featrue extraction / dimensionality reduction \n",
    "\n",
    "n_componets = 150 \n",
    "print \"Extracting the top %d eigenfaces from %d from %d faces \"%(n_components, X_train.shape[0])\n",
    "\n",
    "t0 = time()\n",
    "pca = RandomizedPCA(n_components=n_components, whiten=True).fit(X_train)\n",
    "\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "eigenfaces = pca.components_.reshpae(n_components, h, w)\n",
    "\n",
    "print \"Projecting the input dat on the eigenfaces oothonormal basis\"\n",
    "t0 = time()\n",
    "X_train_pca = pac.transfrom(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print \"done in %0.3fs\" %(time() - t0)\n",
    "\n",
    "\n",
    "print \"Fitting the classifier to the training set\"\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "param_grid = {\n",
    "    'C':[123, 5e3, ]\n",
    "    'gamma': [0.0001, 0.0005, 0.001, ]\n",
    "    \n",
    "    }\n",
    "    \n",
    "# for sklearn version 0.15 or prior , the class_weight parameter value is auto'\n",
    "\n",
    "clf = GridSerchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid)\n",
    "\n",
    "print \"done in %0.0fs\" %(time() - t0)\n",
    "print \"Best estimator found by grid search:\n",
    "print clf.best_estimator_\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Quantitative evalutionof the model quality on the test set \\n\\nprint \"Prediction the people names on the testing set\"\\nt0 = time()\\ny_pred = clf.predict(X_test_pca)\\nprint \"done in %0.3fs\" % (time() - t0)\\n\\nprint classification_report(y_test, y_pred, target_names=target_names)\\nprint confusion_matrix(y_test, y_pred, labels=range(n_classes))\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Quantitative evalutionof the model quality on the test set \n",
    "\n",
    "print \"Prediction the people names on the testing set\"\n",
    "t0 = time()\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "\n",
    "print classification_report(y_test, y_pred, target_names=target_names)\n",
    "print confusion_matrix(y_test, y_pred, labels=range(n_classes))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef plot_gallery(images, titles, h, w, n_row=3, n_col=4):\\n    \"\"\"Helper function to plot a gallery of potraits\"\"\"\\n    pl.figure(figsize=(1.8 * n_col, 2.4 * n_row))\\n    pl.subplts_adjust(bottom0, left=.01, right=.99, top=.90, hspace=.35)\\n    \\n    for i in range(n_row * n_col):\\n        pl.subplot(n_row, n_col, i + 1)\\n        pl.imshow(images[i].reshape((h, w)), cmap=pl.cm.gray)\\n        pl.title(titles[i], size=12)\\n        pl.xticks(())\\n        pl.yticks(())\\n        \\n# plot the result of the prediction on a portion of the test set \\n\\ndef title(y_pred, y_test, target_names, i):\\n\\n    pred_name = target_names[y_pred[i]].rsplit(\\'\\', 1)[-1]\\n    true_name = target_name[y_test[i]].rsplit(\\'\\', 1)[-1]\\n    \\n    return \\'predicted: %s \\n true : %s \\' %(pred_name, true_name)\\n    \\n\\nprediction_titles = [title(y_pred, y_test, target_names, i )\\n                    for i in range(y_pred.shape[0])]\\n                    \\nplot_gallery(X_test, prediction_titles, h, w)\\n\\neigenface_titles = [\"eigenface %d \" % i for i in range(eigenfaces.shpae[0])]\\nplot_gallery(eigenfaces, eigenface_titles, h, w)\\n\\npl.show()\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def plot_gallery(images, titles, h, w, n_row=3, n_col=4):\n",
    "    \"\"\"Helper function to plot a gallery of potraits\"\"\"\n",
    "    pl.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "    pl.subplts_adjust(bottom0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    \n",
    "    for i in range(n_row * n_col):\n",
    "        pl.subplot(n_row, n_col, i + 1)\n",
    "        pl.imshow(images[i].reshape((h, w)), cmap=pl.cm.gray)\n",
    "        pl.title(titles[i], size=12)\n",
    "        pl.xticks(())\n",
    "        pl.yticks(())\n",
    "        \n",
    "# plot the result of the prediction on a portion of the test set \n",
    "\n",
    "def title(y_pred, y_test, target_names, i):\n",
    "\n",
    "    pred_name = target_names[y_pred[i]].rsplit('', 1)[-1]\n",
    "    true_name = target_name[y_test[i]].rsplit('', 1)[-1]\n",
    "    \n",
    "    return 'predicted: %s \\n true : %s ' %(pred_name, true_name)\n",
    "    \n",
    "\n",
    "prediction_titles = [title(y_pred, y_test, target_names, i )\n",
    "                    for i in range(y_pred.shape[0])]\n",
    "                    \n",
    "plot_gallery(X_test, prediction_titles, h, w)\n",
    "\n",
    "eigenface_titles = [\"eigenface %d \" % i for i in range(eigenfaces.shpae[0])]\n",
    "plot_gallery(eigenfaces, eigenface_titles, h, w)\n",
    "\n",
    "pl.show()\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
